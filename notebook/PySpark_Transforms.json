{
	"name": "PySpark_Transforms",
	"properties": {
		"folder": {
			"name": "Stage3"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p1sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "abe3e3d4-14ff-4b68-bb09-8999ba4e1fc9"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/09921ef6-5d34-4a25-a233-84ffa9485571/resourceGroups/rg-oea-tceooeadev01/providers/Microsoft.Synapse/workspaces/syn-oea-tceooeadev01/bigDataPools/spark3p1sm",
				"name": "spark3p1sm",
				"type": "Spark",
				"endpoint": "https://syn-oea-tceooeadev01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p1sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## This note book contains data transformations using Python (PySpark)\r\n",
					"\r\n",
					"This notebook should not be run on its own, rather it is run as part of the Transforms_Connector notebook"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Load all required dataframes"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from pyspark.sql.functions import when, col, sum, percent_rank, substring, trim, regexp_replace, length\r\n",
					"from pyspark.sql.window import Window\r\n",
					"import databricks.koalas as ks"
				],
				"execution_count": 26
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sourcep = oea.stage2p\r\n",
					"source3p = oea.stage3p\r\n",
					"\r\n",
					"# source tables from Stage2\r\n",
					"DMPersonDemographic_df = spark.read.load(sourcep + \"/student/DMPersonDemographic_pseudo\", format='delta')\r\n",
					"EYAnswers_df = spark.read.load(sourcep + \"/EarlyYearsAnswers/EarlyYearsAnswers_pseudo\", format='delta')\r\n",
					"\r\n",
					"# source tables from Stage3\r\n",
					"EarlyYearsResults_df = spark.read.load(source3p + \"/pilot/EarlyYearsResults_pseudo\", format='delta')\r\n",
					"EYResultsYear2_df = spark.read.load(source3p + \"/pilot/EarlyYearsResultsYear2_pseudo\", format='delta')\r\n",
					""
				],
				"execution_count": 28
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Split the DMPersonDemographic into DMStudentDemographic and DMStaffDemographic"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Clean up the table and remove null and unnecessary columns\r\n",
					"\r\n",
					"df = DMPersonDemographic_df.filter(DMPersonDemographic_df.Ceider != -1) \\\r\n",
					"                .drop(\"UsualTransport\") \\\r\n",
					"                .drop(\"ContactNotesBH\") \\\r\n",
					"                .drop(\"ContactNotesAH\") \\\r\n",
					"                .drop(\"OrganisationUserId\") \\\r\n",
					"                .drop(\"ProgramCode\") \\\r\n",
					"                .drop(\"Disability_YN\") \\\r\n",
					"                .drop(\"DisabilityFundedInt\") \\\r\n",
					"                .drop(\"ReceivesESL_YN\") \\\r\n",
					"                .drop(\"ReceivesESLInt\") \\\r\n",
					"                .drop(\"RequiresESL_YN\") \\\r\n",
					"                .drop(\"RequresESLInt\") \\\r\n",
					"                .drop(\"LBOTE_YN\") \\\r\n",
					"                .drop(\"LBOTEInt\") \\\r\n",
					"                .drop(\"AccessRestrictions_YN\")\r\n",
					"\r\n",
					"cleaned_df = df.withColumn(\"ATSIId\", when(df.ATSIId > 4, 4).when(df.ATSIId < 1, 4).otherwise(df.ATSIId))\r\n",
					"\r\n",
					"# now split the demographic information into two tables \r\n",
					"DMStudentDemographic_df = cleaned_df.filter((cleaned_df.PersonType == \"Student\"))\r\n",
					"DMStaffDemographic_df = cleaned_df.filter((cleaned_df.PersonType == \"Staff\"))"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# Create the early years transformations for aggregate pre/post rest results\r\n",
					"\r\n",
					"EarlyYearsResultsTotals_df = EarlyYearsResults_df.groupBy(\"CampusID\", \"Ceider\",\t\"ClassID\", \"Year\", \"YearLevel\", \"TestLevel\").agg(sum(EarlyYearsResults_df.Ques1+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques2+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques3+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques4+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques5+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques6+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques7+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques8+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques9+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques10+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques11+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques12+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques13+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques14+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques15+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques16+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques17+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques18+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques19+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques20).alias(\"NumericTotal\"), \r\n",
					"                                                                                                                sum(EarlyYearsResults_df.Ques21+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques22+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques23+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques24+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques25+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques26+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques27+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques28+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques29+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques30+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques31+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques32+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques33+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques34+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques35+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques36+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques37+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques38+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques39+\r\n",
					"                                                                                                                EarlyYearsResults_df.Ques40).alias(\"LiteracyTotal\"))\r\n",
					"\r\n",
					"\r\n",
					"EarlyYearsResultsTotals_df = EarlyYearsResultsTotals_df.withColumn(\"NumeracyPercentile\", percent_rank().over(Window.orderBy(\"NumericTotal\")))\r\n",
					"\r\n",
					"EarlyYearsResultsTotals_df = EarlyYearsResultsTotals_df.withColumn(\"LiteracyPercentile\", percent_rank().over(Window.orderBy(\"LiteracyTotal\")))\r\n",
					""
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# this table will pivot the early years result Questions from columns to rows \r\n",
					"\r\n",
					"df = EarlyYearsResults_df.to_koalas().melt(id_vars=['CampusID', 'Ceider', 'ClassID', 'Year', 'YearLevel', 'TestLevel'],\r\n",
					"                                            value_vars=['Ques1', 'Ques2', 'Ques3', 'Ques4', 'Ques5', 'Ques6', 'Ques7', 'Ques8', 'Ques9', 'Ques10',\r\n",
					"                                                        'Ques11', 'Ques12', 'Ques13', 'Ques14', 'Ques15', 'Ques16', 'Ques17', 'Ques18', 'Ques19', 'Ques20',\r\n",
					"                                                        'Ques21', 'Ques22', 'Ques23', 'Ques24', 'Ques25', 'Ques26', 'Ques27', 'Ques28', 'Ques29', 'Ques30',\r\n",
					"                                                        'Ques31', 'Ques32', 'Ques33', 'Ques34', 'Ques35', 'Ques36', 'Ques37', 'Ques38', 'Ques39', 'Ques40'],\r\n",
					"                                            var_name=\"Question\",\r\n",
					"                                            value_name = \"Result\")\r\n",
					"\r\n",
					"EarlyYearsResultsLong_df = df.to_spark()\r\n",
					""
				],
				"execution_count": 52
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# convert the answer table to long format (same as the year 2 student answers)\r\n",
					"\r\n",
					"df = EYAnswers_df.to_koalas().melt(id_vars=['Year', 'Question'],\r\n",
					"                                            value_vars=['Numeracy', 'Literacy'],\r\n",
					"                                            var_name=\"QuestionType\",\r\n",
					"                                            value_name = \"Answer\")\r\n",
					"\r\n",
					"EYAnswers_df = df.to_spark()\r\n",
					""
				],
				"execution_count": 29
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# remove the test rows\r\n",
					"EYResultsYear2_df = EYResultsYear2_df.filter(EYResultsYear2_df.Ceider != 12345)\r\n",
					"EYResultsYear2_df = EYResultsYear2_df.filter(EYResultsYear2_df.Ceider != 111111)\r\n",
					"\r\n",
					"# seperate numeracy and literacy results\r\n",
					"\r\n",
					"EYResultsYear2_Numeracy = EYResultsYear2_df.filter(EYResultsYear2_df.QuestionType == 'Numeracy')\r\n",
					"\r\n",
					"EYResultsYear2_Literacy = EYResultsYear2_df.filter(EYResultsYear2_df.QuestionType == 'Literacy')\r\n",
					"\r\n",
					"# get the Ceider and ClassID columns only\r\n",
					"EYResultsYear2_Literacy_Reduced = EYResultsYear2_Literacy.select(col(\"Ceider\").alias(\"xCeider\"), col(\"ClassID\").alias(\"xClassID\"))\r\n",
					"\r\n",
					"# join the literacy classID's to the numeracy table\r\n",
					"\r\n",
					"joined_class_df = EYResultsYear2_Numeracy.join(EYResultsYear2_Literacy_Reduced, EYResultsYear2_Numeracy['Ceider'] == EYResultsYear2_Literacy_Reduced['xCeider'] )\r\n",
					"\r\n",
					"# remove generic classID's\r\n",
					"\r\n",
					"joined_class_df = joined_class_df.withColumn(\"ClassID\", when(col(\"ClassID\") == \"GEN2\", col(\"xClassID\")).otherwise(col(\"ClassID\")))\r\n",
					"\r\n",
					"joined_class_df = joined_class_df.withColumn(\"xClassID\", when(col(\"xClassID\") == \"GEN2\", col(\"ClassID\")).otherwise(col(\"xClassID\")))\r\n",
					"\r\n",
					"# get the updated classID's\r\n",
					"\r\n",
					"newclassid_df = joined_class_df.select(col(\"xCeider\"), col(\"xClassID\"))\r\n",
					"\r\n",
					"# apply the new class ID's to the literacy table as well\r\n",
					"\r\n",
					"updated_literacy_df = EYResultsYear2_Literacy.join(newclassid_df, [col('Ceider') == col('xCeider')] )\r\n",
					"\r\n",
					"updated_literacy_df = updated_literacy_df.drop(\"xCeider\").drop(\"ClassID\")\r\n",
					"\r\n",
					"updated_literacy_df = updated_literacy_df.withColumnRenamed(\"xClassID\", \"ClassID\")\r\n",
					"\r\n",
					"updated_numeracy_df = joined_class_df.drop(\"xCeider\").drop(\"ClassID\")\r\n",
					"\r\n",
					"updated_numeracy_df = updated_numeracy_df.withColumnRenamed(\"xClassID\", \"ClassID\")\r\n",
					"\r\n",
					"EYResultsYear2Cleaned_df = updated_literacy_df.union(updated_numeracy_df)\r\n",
					"\r\n",
					"#display(EYResultsYear2Cleaned_df)"
				],
				"execution_count": 32
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# wide to long conversion\r\n",
					"\r\n",
					"df = EYResultsYear2Cleaned_df.to_koalas().melt(id_vars=['CampusID', 'Ceider', 'ClassID', 'QuestionType', 'Status', 'StudentEmailID', 'StudentName', 'TeacherEmailID', 'TeacherName', 'Year', 'YearLevel', 'TestLevel'],\r\n",
					"                                            value_vars=['Ques1', 'Ques2', 'Ques3', 'Ques4', 'Ques5', 'Ques6', 'Ques7', 'Ques8', 'Ques9', 'Ques10',\r\n",
					"                                                        'Ques11', 'Ques12', 'Ques13', 'Ques14', 'Ques15', 'Ques16', 'Ques17', 'Ques18', 'Ques19', 'Ques20',\r\n",
					"                                                        'Ques21', 'Ques22', 'Ques23', 'Ques24', 'Ques25'],\r\n",
					"                                            var_name=\"Question\",\r\n",
					"                                            value_name = \"StudentAnswer\")\r\n",
					"\r\n",
					"EYResultsYear2Long_df = df.to_spark()\r\n",
					"\r\n",
					"EYResultsYear2Long_df = EYResultsYear2Long_df.withColumn(\"Question\", substring(\"Question\", 5, len(\"Question\")-4))\r\n",
					"\r\n",
					"\r\n",
					"# combine the student answers with the actual answers table\r\n",
					"\r\n",
					"EYAnswers_df = EYAnswers_df.withColumnRenamed('Year', 'xYear').withColumnRenamed('Question', 'xQuestion').withColumnRenamed('QuestionType', 'xQuestionType')\r\n",
					"\r\n",
					"joined_df = EYResultsYear2Long_df.join(EYAnswers_df, [col('Year') == col('xYear'), col('Question') == col('xQuestion'), col('QuestionType') == col('xQuestionType')], how='left')\r\n",
					"\r\n",
					"joinedcleaned_df = joined_df.drop('xYear').drop('xQuestion').drop('xQuestionType')\r\n",
					"\r\n",
					"# do the correction by comparing StudentAnswer to the real Answer\r\n",
					"EYResultsYear2LongFinal_df = joinedcleaned_df.withColumn('Result', when(trim(joinedcleaned_df.StudentAnswer) == trim(joinedcleaned_df.Answer), 1).otherwise(0))\r\n",
					""
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"# create the totals dataframe for year 2\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Numeracy_df = EYResultsYear2LongFinal_df.filter(EYResultsYear2LongFinal_df.QuestionType == 'Numeracy')\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Literacy_df = EYResultsYear2LongFinal_df.filter(EYResultsYear2LongFinal_df.QuestionType == 'Literacy')\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Numeracy_df = EarlyYearsResultsTotalsYear2Numeracy_df.groupBy(\"CampusID\", \"Ceider\",\t\"ClassID\", \"Year\", \"YearLevel\", \"TestLevel\").agg(sum(EarlyYearsResultsTotalsYear2Numeracy_df.Result).alias(\"NumeracyTotal\"))\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Literacy_df = EarlyYearsResultsTotalsYear2Literacy_df.groupBy(\"CampusID\", \"Ceider\",\t\"ClassID\", \"Year\", \"YearLevel\", \"TestLevel\").agg(sum(EarlyYearsResultsTotalsYear2Literacy_df.Result).alias(\"LiteracyTotal\"))\r\n",
					"\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Literacy_df = EarlyYearsResultsTotalsYear2Literacy_df.withColumnRenamed(\"CampusID\", \"xCampusID\")\\\r\n",
					"                                                                                    .withColumnRenamed(\"Ceider\", \"xCeider\")\\\r\n",
					"                                                                                    .withColumnRenamed(\"ClassID\", \"xClassID\")\\\r\n",
					"                                                                                    .withColumnRenamed(\"Year\", \"xYear\")\\\r\n",
					"                                                                                    .withColumnRenamed(\"YearLevel\", \"xYearLevel\")\\\r\n",
					"                                                                                    .withColumnRenamed(\"TestLevel\", \"xTestLevel\")\r\n",
					"\r\n",
					"\r\n",
					"# join the numeracy and literacy results \r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Joined_df = EarlyYearsResultsTotalsYear2Numeracy_df.join(EarlyYearsResultsTotalsYear2Literacy_df, [col('CampusID') == col('xCampusID'),\r\n",
					"                                                                                                                                col('Ceider') == col('xCeider'),\r\n",
					"                                                                                                                                col('ClassID') == col('xClassID'),\r\n",
					"                                                                                                                                col('Year') == col('xYear'),\r\n",
					"                                                                                                                                col('YearLevel') == col('xYearLevel'),\r\n",
					"                                                                                                                                col('TestLevel') == col('xTestLevel')\r\n",
					"                                                                                                                                ])\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Joined_df = EarlyYearsResultsTotalsYear2Joined_df.drop('xCampusID')\\\r\n",
					"                                                                                .drop('xCeider')\\\r\n",
					"                                                                                .drop('xClassID')\\\r\n",
					"                                                                                .drop('xYear')\\\r\n",
					"                                                                                .drop('xYearLevel')\\\r\n",
					"                                                                                .drop('xTestLevel')\r\n",
					"\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Joined_df = EarlyYearsResultsTotalsYear2Joined_df.withColumn(\"NumeracyPercentile\", percent_rank().over(Window.orderBy(\"NumeracyTotal\")))\r\n",
					"\r\n",
					"EarlyYearsResultsTotalsYear2Joined_df = EarlyYearsResultsTotalsYear2Joined_df.withColumn(\"LiteracyPercentile\", percent_rank().over(Window.orderBy(\"LiteracyTotal\")))\r\n",
					"\r\n",
					"\r\n",
					"#display(EarlyYearsResultsTotalsYear2Joined_df)"
				],
				"execution_count": 64
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Save the new tables "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"saveToTarget(DMStudentDemographic_df, destination_p, f'{version}/DMStudentDemographic_pseudo')\r\n",
					"saveToTarget(DMStaffDemographic_df, destination_p, f'{version}/DMStaffDemographic_pseudo')\r\n",
					"saveToTarget(EarlyYearsResultsTotals_df, destination_p, f'{version}/EarlyYearsResultsTotals_pseudo')\r\n",
					"saveToTarget(EarlyYearsResultsLong_df, destination_p, f'{version}/EarlyYearsResultsLong_pseudo')\r\n",
					"saveToTarget(EYResultsYear2LongFinal_df, destination_p, f'{version}/EarlyYearsResultsYear2Long_pseudo')\r\n",
					"\r\n",
					"#saveToTarget(EarlyYearsResultsTotalsYear2Numeracy_df, destination_p, f'{version}/EarlyYearsResultsTotalsYear2Numeracy_pseudo')\r\n",
					"#saveToTarget(EarlyYearsResultsTotalsYear2Literacy_df, destination_p, f'{version}/EarlyYearsResultsTotalsYear2Literacy_pseudo')\r\n",
					"\r\n",
					"saveToTarget(EarlyYearsResultsTotalsYear2Joined_df, destination_p, f'{version}/EarlyYearsResultsTotalsYear2Joined_pseudo')"
				],
				"execution_count": 42
			}
		]
	}
}