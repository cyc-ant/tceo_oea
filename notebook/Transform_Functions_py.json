{
	"name": "Transform_Functions_py",
	"properties": {
		"folder": {
			"name": "Stage3"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p1sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "a0af35e2-8af6-4f1f-8b4f-b65676f67383"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/09921ef6-5d34-4a25-a233-84ffa9485571/resourceGroups/rg-oea-tceooeadev01/providers/Microsoft.Synapse/workspaces/syn-oea-tceooeadev01/bigDataPools/spark3p1sm",
				"name": "spark3p1sm",
				"type": "Spark",
				"endpoint": "https://syn-oea-tceooeadev01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p1sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import when, max, regexp_replace, col, concat_ws, substring, instr"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMYearLevel_pseudo(df):\r\n",
					"\r\n",
					"    df = df.withColumn(\"DisplayName\", when(df.BusinessDesc == \"Unknown\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"Ungraded\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"SecondaryUngraded\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"PrimaryUngraded\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"Childcare\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"4yo Kindergarten\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"3yo Kindergarten\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"TwoYearsBeforeYear1\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"Pre-Year 1\", \"Prep\")\r\n",
					"                                        .when(df.BusinessDesc == \"Pre-School\", \"Prep\")\r\n",
					"                                        .when(df.BusinessDesc == \"OneYearBeforeYear1\", \"Prep\")\r\n",
					"                                        .otherwise(df.BusinessDesc)\r\n",
					"                                        )\r\n",
					"\r\n",
					"    return df"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMCampus_pseudo(df):\r\n",
					"        df = df.filter(df.DioceseName == 'Townsville') \\\r\n",
					"                .filter(df.SchoolName !=  'Townsville Catholic Education Office') \\\r\n",
					"                .filter(df.SchoolName !=  'Canossa Convent School') \\\r\n",
					"                .filter(df.SchoolName !=  'St Patrick\\'s College Townsville') \\\r\n",
					"                .filter(df.SchoolId != 6814)\r\n",
					"        \r\n",
					"        # load the school list to get the 'area' into DMCampus\r\n",
					"        sourcep = oea.stage2p\r\n",
					"        school_df = spark.read.load(sourcep + \"/_SupportData/SchoolList_pseudo\", format='delta')\r\n",
					"        \r\n",
					"        school_df = school_df.withColumnRenamed('SchoolId', 'xSchoolId')\r\n",
					"\r\n",
					"        df = df.withColumnRenamed('SchoolName', 'xSchoolName')\r\n",
					"\r\n",
					"        newdf = df.join(school_df, df.SchoolId == school_df.xSchoolId, \"inner\")\r\n",
					"        \r\n",
					"        final_df = newdf.select(col(\"SchoolId\"), col(\"SchoolName\"), col(\"Area\"), col(\"Location\"), \\\r\n",
					"                                col(\"Team\"), col(\"SchoolType\"), col(\"Boarding\"), col(\"SMYL\"), col(\"LastICSEA\"), \\\r\n",
					"                                col(\"SKCampus\"), col(\"BKCampusId\"), col(\"CampusSuburbAndName\"), col(\"SchoolSuburbAndName\"))\r\n",
					"\r\n",
					"        final_df = final_df.withColumn(\"SchoolNameAndArea\", concat_ws(\" - \", \"SchoolName\", \"Area\"))\r\n",
					"\r\n",
					"        return final_df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMDate_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmdate_pseudo')\r\n",
					"\r\n",
					"    calendar_df = spark.read.load(sourcep + \"/ACER/DMCalendarYear_pseudo\", format='delta')\r\n",
					"\r\n",
					"    calendar_df.createOrReplaceTempView('vw_df_calendar')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select d.*, c.skyear from vw_df_dmdate_pseudo d left join vw_df_calendar c on d.year = c.year where d.year >= 2008 and d.year <= 2030\")\r\n",
					"\r\n",
					"    return final_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMStudent_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmstudent_pseudo')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select * from vw_df_dmstudent_pseudo where length(bksourcestudentid) = 36\")\r\n",
					"\r\n",
					"    return final_df"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMNAPLAN_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmnaplan_pseudo')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select * from vw_df_dmnaplan_pseudo where PersistentStudentID <> -1\")\r\n",
					"\r\n",
					"    return final_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMPersonDemographic_pseudo(df):\r\n",
					"\r\n",
					"    final_df = df.filter(df.Ceider != -1) \\\r\n",
					"                .filter( (df.PersonType == \"Student\") | (df.PersonType == \"Staff\") ) \\\r\n",
					"                .drop(\"UsualTransport\") \\\r\n",
					"                .drop(\"ContactNotesBH\") \\\r\n",
					"                .drop(\"ContactNotesAH\") \\\r\n",
					"                .drop(\"OrganisationUserId\") \\\r\n",
					"                .drop(\"ProgramCode\") \\\r\n",
					"                .drop(\"Disability_YN\") \\\r\n",
					"                .drop(\"DisabilityFundedInt\") \\\r\n",
					"                .drop(\"ReceivesESL_YN\") \\\r\n",
					"                .drop(\"ReceivesESLInt\") \\\r\n",
					"                .drop(\"RequiresESL_YN\") \\\r\n",
					"                .drop(\"RequresESLInt\") \\\r\n",
					"                .drop(\"LBOTE_YN\") \\\r\n",
					"                .drop(\"LBOTEInt\") \\\r\n",
					"                .drop(\"AccessRestrictions_YN\")\r\n",
					"\r\n",
					"    return final_df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					}
				},
				"source": [
					"%%pyspark\r\n",
					"\r\n",
					"def DMFactPATResults_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmfactpatresults_pseudo')\r\n",
					"\r\n",
					"    datedetails_df = spark.read.load(sourcep + \"/ACER/DMPATStudentTestGrouping_pseudo\", format='delta')\r\n",
					"\r\n",
					"    datedetails_df.createOrReplaceTempView('vw_df_dmpatstudenttestgrouping')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select a.*, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, scalescore, datecomplete, timecomplete, combineddatetime, max(skpatresults) as maxskpatresults from (select a.skpatresults, a.skyear, a.skacerstudent, a.skpattest, a.skcampus,  a.ScaleScore,  b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, combineddatetime, max(scalescore) as maxscalescore from (select a.skyear, a.skacerstudent, a.skpattest, a.skcampus,  a.ScaleScore,  b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, max(concat(datecomplete, ' ', right(left(timecomplete, 10), 8))) as latestdate from (select a.*, orig.skpatstudenttestgrouping, orig.skacerstanine, ScaleScore, skpatresults, b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from (select skyear, skacerstudent, skpattest, skcampus, count(*) as counttotal from vw_df_dmfactpatresults_pseudo where skpattest not in (43, 54, 65, 66, 76, 79, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112) group by skyear, skacerstudent, skpattest, skcampus) a left join vw_df_dmfactpatresults_pseudo orig on a.skyear = orig.skyear and a.skacerstudent = orig.skacerstudent and a.skpattest = orig.skpattest and a.skcampus = orig.skcampus left join vw_df_dmpatstudenttestgrouping b on orig.skpatstudenttestgrouping = b.skpatstudenttestgrouping) total group by skyear, skacerstudent, skpattest, skcampus) inner1 on a.skyear = inner1.skyear and a.skacerstudent = inner1.SKACERStudent and a.SKPATTest = inner1.SKPATTest and a.SKCampus = inner1.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner1.latestdate ) inner2 group by skyear, skacerstudent, skpattest, skcampus, combineddatetime ) inner3 on a.skyear = inner3.skyear and a.skacerstudent = inner3.SKACERStudent and a.SKPATTest = inner3.SKPATTest and a.SKCampus = inner3.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner3.combineddatetime ) inner4 group by skyear, skacerstudent, skpattest, skcampus, scalescore, datecomplete, timecomplete, combineddatetime ) inner5 on a.skyear = inner5.skyear and a.skacerstudent = inner5.SKACERStudent and a.SKPATTest = inner5.SKPATTest and a.SKCampus = inner5.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner5.combineddatetime and a.SKPATResults = inner5.maxskpatresults\")\r\n",
					"\r\n",
					"    return final_df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def StudentLevel_pseudo(df):\r\n",
					"\r\n",
					"    df = df.withColumn(\"GenderSifCode\", when(df.sex == \"F\", \"2\")\r\n",
					"                                        .when(df.sex == \"M\", \"1\")\r\n",
					"                                        .otherwise(\"9\")\r\n",
					"                                        )\r\n",
					"\r\n",
					"\r\n",
					"    df = df.withColumn(\"AtsiSifId\", when(df.indigenous == \"A\", \"1\")\r\n",
					"                                        .when(df.indigenous == \"T\", \"2\")\r\n",
					"                                        .when(df.indigenous == \"B\", \"3\")\r\n",
					"                                        .when(df.indigenous == \"N\", \"4\")\r\n",
					"                                        .otherwise(\"9\")\r\n",
					"                                        )\r\n",
					"\r\n",
					"    return df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def CompassODSStudentOrganisationMilestones_pseudo(df):\r\n",
					"\r\n",
					"    hyphen_index = instr(df['OrganisationName'], '-') + 1\r\n",
					"\r\n",
					"    df = df.withColumn('xOrganisationName', substring(df['OrganisationName'], 1, hyphen_index)).drop('OrganisationName')\r\n",
					"\r\n",
					"    df = df.withColumnRenamed('xOrganisationName', 'OrganisationName')\r\n",
					"\r\n",
					"    return df\r\n",
					"\r\n",
					"    \r\n",
					""
				],
				"execution_count": null
			}
		]
	}
}