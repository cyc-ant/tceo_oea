{
	"name": "Transform_Functions_py",
	"properties": {
		"folder": {
			"name": "Stage3"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p1sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "d88bf9ea-7ec4-4975-b68a-78d52bf1f240"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/09921ef6-5d34-4a25-a233-84ffa9485571/resourceGroups/rg-oea-tceooeadev01/providers/Microsoft.Synapse/workspaces/syn-oea-tceooeadev01/bigDataPools/spark3p1sm",
				"name": "spark3p1sm",
				"type": "Spark",
				"endpoint": "https://syn-oea-tceooeadev01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p1sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import when, max, regexp_replace, col, concat_ws, udf, lit, regexp_replace\r\n",
					"from pyspark.sql.types import StringType"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMYearLevel_pseudo(df):\r\n",
					"\r\n",
					"    df = df.withColumn(\"DisplayName\", when(df.BusinessDesc == \"Unknown\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"Ungraded\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"SecondaryUngraded\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"PrimaryUngraded\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"Childcare\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"4yo Kindergarten\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"3yo Kindergarten\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"TwoYearsBeforeYear1\", \"\")\r\n",
					"                                        .when(df.BusinessDesc == \"Pre-Year 1\", \"Prep\")\r\n",
					"                                        .when(df.BusinessDesc == \"Pre-School\", \"Prep\")\r\n",
					"                                        .when(df.BusinessDesc == \"OneYearBeforeYear1\", \"Prep\")\r\n",
					"                                        .otherwise(df.BusinessDesc)\r\n",
					"                        )\r\n",
					"\r\n",
					"    return df"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMCampus_pseudo(df):\r\n",
					"        df = df.filter(df.DioceseName == 'Townsville') \\\r\n",
					"                .filter(df.SchoolName !=  'Townsville Catholic Education Office') \\\r\n",
					"                .filter(df.SchoolName !=  'Canossa Convent School') \\\r\n",
					"                .filter(df.SchoolName !=  'St Patrick\\'s College Townsville') \\\r\n",
					"                .filter(df.SchoolId != 6814)\r\n",
					"        \r\n",
					"        # load the school list to get the 'area' into DMCampus\r\n",
					"        sourcep = oea.stage2p\r\n",
					"        school_df = spark.read.load(sourcep + \"/_SupportData/SchoolList_pseudo\", format='delta')\r\n",
					"        \r\n",
					"        school_df = school_df.withColumnRenamed('SchoolId', 'xSchoolId')\r\n",
					"\r\n",
					"        df = df.withColumnRenamed('SchoolName', 'xSchoolName')\r\n",
					"\r\n",
					"        newdf = df.join(school_df, df.SchoolId == school_df.xSchoolId, \"inner\")\r\n",
					"        \r\n",
					"        final_df = newdf.select(col(\"SchoolId\"), col(\"SchoolName\"), col(\"Area\"), col(\"Location\"), \\\r\n",
					"                                col(\"Team\"), col(\"SchoolType\"), col(\"Boarding\"), col(\"SMYL\"), col(\"LastICSEA\"), \\\r\n",
					"                                col(\"SKCampus\"), col(\"BKCampusId\"), col(\"CampusSuburbAndName\"), col(\"SchoolSuburbAndName\"))\r\n",
					"\r\n",
					"        final_df = final_df.withColumn(\"SchoolNameAndArea\", concat_ws(\" - \", \"SchoolName\", \"Area\"))\r\n",
					"\r\n",
					"        return final_df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMDate_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmdate_pseudo')\r\n",
					"\r\n",
					"    calendar_df = spark.read.load(sourcep + \"/ACER/DMCalendarYear_pseudo\", format='delta')\r\n",
					"\r\n",
					"    calendar_df.createOrReplaceTempView('vw_df_calendar')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select d.*, c.skyear from vw_df_dmdate_pseudo d left join vw_df_calendar c on d.year = c.year where d.year >= 2008 and d.year <= 2030\")\r\n",
					"\r\n",
					"    return final_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMStudent_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmstudent_pseudo')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select * from vw_df_dmstudent_pseudo where length(bksourcestudentid) = 36\")\r\n",
					"\r\n",
					"    return final_df"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMNAPLAN_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmnaplan_pseudo')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select * from vw_df_dmnaplan_pseudo where PersistentStudentID <> -1\")\r\n",
					"\r\n",
					"    return final_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMPersonDemographic_pseudo(df):\r\n",
					"\r\n",
					"    final_df = df.filter(df.Ceider != -1) \\\r\n",
					"                .filter( (df.PersonType == \"Student\") | (df.PersonType == \"Staff\") ) \\\r\n",
					"                .drop(\"UsualTransport\") \\\r\n",
					"                .drop(\"ContactNotesBH\") \\\r\n",
					"                .drop(\"ContactNotesAH\") \\\r\n",
					"                .drop(\"OrganisationUserId\") \\\r\n",
					"                .drop(\"ProgramCode\") \\\r\n",
					"                .drop(\"Disability_YN\") \\\r\n",
					"                .drop(\"DisabilityFundedInt\") \\\r\n",
					"                .drop(\"ReceivesESL_YN\") \\\r\n",
					"                .drop(\"ReceivesESLInt\") \\\r\n",
					"                .drop(\"RequiresESL_YN\") \\\r\n",
					"                .drop(\"RequresESLInt\") \\\r\n",
					"                .drop(\"LBOTE_YN\") \\\r\n",
					"                .drop(\"LBOTEInt\") \\\r\n",
					"                .drop(\"AccessRestrictions_YN\")\r\n",
					"\r\n",
					"    return final_df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"microsoft": {
						"language": "python"
					}
				},
				"source": [
					"%%pyspark\r\n",
					"\r\n",
					"def DMFactPATResults_pseudo(df):\r\n",
					"\r\n",
					"    sourcep = oea.stage2p\r\n",
					"\r\n",
					"    df.createOrReplaceTempView('vw_df_dmfactpatresults_pseudo')\r\n",
					"\r\n",
					"    datedetails_df = spark.read.load(sourcep + \"/ACER/DMPATStudentTestGrouping_pseudo\", format='delta')\r\n",
					"\r\n",
					"    datedetails_df.createOrReplaceTempView('vw_df_dmpatstudenttestgrouping')\r\n",
					"\r\n",
					"    final_df = spark.sql(\"select a.*, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, scalescore, datecomplete, timecomplete, combineddatetime, max(skpatresults) as maxskpatresults from (select a.skpatresults, a.skyear, a.skacerstudent, a.skpattest, a.skcampus,  a.ScaleScore,  b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, combineddatetime, max(scalescore) as maxscalescore from (select a.skyear, a.skacerstudent, a.skpattest, a.skcampus,  a.ScaleScore,  b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, max(concat(datecomplete, ' ', right(left(timecomplete, 10), 8))) as latestdate from (select a.*, orig.skpatstudenttestgrouping, orig.skacerstanine, ScaleScore, skpatresults, b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from (select skyear, skacerstudent, skpattest, skcampus, count(*) as counttotal from vw_df_dmfactpatresults_pseudo where skpattest not in (43, 54, 65, 66, 76, 79, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112) group by skyear, skacerstudent, skpattest, skcampus) a left join vw_df_dmfactpatresults_pseudo orig on a.skyear = orig.skyear and a.skacerstudent = orig.skacerstudent and a.skpattest = orig.skpattest and a.skcampus = orig.skcampus left join vw_df_dmpatstudenttestgrouping b on orig.skpatstudenttestgrouping = b.skpatstudenttestgrouping) total group by skyear, skacerstudent, skpattest, skcampus) inner1 on a.skyear = inner1.skyear and a.skacerstudent = inner1.SKACERStudent and a.SKPATTest = inner1.SKPATTest and a.SKCampus = inner1.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner1.latestdate ) inner2 group by skyear, skacerstudent, skpattest, skcampus, combineddatetime ) inner3 on a.skyear = inner3.skyear and a.skacerstudent = inner3.SKACERStudent and a.SKPATTest = inner3.SKPATTest and a.SKCampus = inner3.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner3.combineddatetime ) inner4 group by skyear, skacerstudent, skpattest, skcampus, scalescore, datecomplete, timecomplete, combineddatetime ) inner5 on a.skyear = inner5.skyear and a.skacerstudent = inner5.SKACERStudent and a.SKPATTest = inner5.SKPATTest and a.SKCampus = inner5.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner5.combineddatetime and a.SKPATResults = inner5.maxskpatresults\")\r\n",
					"\r\n",
					"    return final_df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def CompassODSStudentOrganisationMilestones_pseudo(df):\r\n",
					"\r\n",
					"    # this will get a the first substring up to the first hyphen \r\n",
					"    get_substring_udf = udf(lambda x: x.split(\"-\")[0] if \"-\" in x else x, StringType())\r\n",
					"\r\n",
					"    df = df.withColumn('xOrganisationName', get_substring_udf(col('OrganisationName')))\r\n",
					"    df = df.drop('OrganisationName')\r\n",
					"    df = df.withColumnRenamed('xOrganisationName', 'OrganisationName')\r\n",
					"\r\n",
					"    return df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Early Years Testing"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def EarlyYearsResults_pseudo(df):\r\n",
					"\r\n",
					"    # filter out the in-progress tests (incomplete tests)\r\n",
					"    df = df.filter(df.Status == \"Completed\")\r\n",
					"\r\n",
					"    question_columns = [item for item in df.columns if item.startswith('Ques')]\r\n",
					"\r\n",
					"    for col in question_columns:\r\n",
					"            df = df.withColumn(col, when(df[col] == 'Correct', lit('1'))\r\n",
					"                                .otherwise(when(df[col] == 'Incorrect', lit('0'))\r\n",
					"                                .otherwise(when(df[col] == 'Used structure correctly', lit('1'))\r\n",
					"                                .otherwise(when(df[col] == 'Used structure incorrectly', lit('0'))\r\n",
					"                                .otherwise(when(df[col] == 'Other response', lit('0')))))))\r\n",
					"  \r\n",
					"    # replace errors in classes\r\n",
					"    df = df.withColumn('ClassID', regexp_replace('ClassID', 'GENP_PREP', '00GENP01'))\r\n",
					"    df = df.withColumn('ClassID', regexp_replace('ClassID', 'GEN1_Year 1', '01GEN101'))\r\n",
					"   \r\n",
					"    return df\r\n",
					"\r\n",
					"\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def EarlyYearsResultsYear2_pseudo(df):\r\n",
					"\r\n",
					"    # filter out the in-progress tests (incomplete tests)\r\n",
					"    df = df.filter(df.Status == \"Completed\")\r\n",
					"\r\n",
					"    df = df.withColumn('Ques1', when(df.Ques1.substr(1,5) == 'could', lit('could good')).otherwise(df.Ques1))\r\n",
					"\r\n",
					"    df = df.withColumn('ClassID', regexp_replace('ClassID', 'GEN2_Year 2', '02GEN201'))\r\n",
					"\r\n",
					"    #df = df.withColumn('ClassId', when(df.Ceider == '769425243', lit('GEN2_02C')).otherwise(df.ClassID))\r\n",
					"\r\n",
					"    return df\r\n",
					"\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Senior Outcomes "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def StudentLevel_pseudo(df):\r\n",
					"\r\n",
					"    df = df.withColumn(\"GenderSifCode\", when(df.sex == \"F\", \"2\")\r\n",
					"                                        .when(df.sex == \"M\", \"1\")\r\n",
					"                                        .otherwise(\"9\")\r\n",
					"                                        )\r\n",
					"\r\n",
					"\r\n",
					"    df = df.withColumn(\"AtsiSifId\", when(df.indigenous == \"A\", \"1\")\r\n",
					"                                        .when(df.indigenous == \"T\", \"2\")\r\n",
					"                                        .when(df.indigenous == \"B\", \"3\")\r\n",
					"                                        .when(df.indigenous == \"N\", \"4\")\r\n",
					"                                        .otherwise(\"9\")\r\n",
					"                                        )\r\n",
					"\r\n",
					"    return df\r\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def ATAR_pseudo(df):\r\n",
					"    df = df.withColumn(\"Result_Bucket\", \r\n",
					"                        when(df.Given_Name == \"No Consent\", \"No Consent\")\r\n",
					"                        .when(df.Given_Name == \"Vocational Pathway\", \"Vocational Pathway\")\r\n",
					"                        .otherwise(when(df.ATAR < 30, \"< 30\")\r\n",
					"                                    .when(((df.ATAR < 40) & (df.ATAR >= 30)), \"39.95 - 30\")\r\n",
					"                                    .when(((df.ATAR < 50) & (df.ATAR >= 40)), \"49.95 - 40\")\r\n",
					"                                    .when(((df.ATAR < 60) & (df.ATAR >= 50)), \"59.95 - 50\")\r\n",
					"                                    .when(((df.ATAR < 70) & (df.ATAR >= 60)), \"69.95 - 60\")\r\n",
					"                                    .when(((df.ATAR < 80) & (df.ATAR >= 70)), \"79.95 - 70\")\r\n",
					"                                    .when(((df.ATAR < 90) & (df.ATAR >= 80)), \"89.95 - 80\")\r\n",
					"                                    .when(df.ATAR >= 90, \"99.95 - 90\")\r\n",
					"                                )\r\n",
					"                    )\r\n",
					"\r\n",
					"    df = df.withColumn(\"Order\", \r\n",
					"                        when(df.Result_Bucket == \"< 30\", 8)\r\n",
					"                        .when(df.Result_Bucket == \"39.95 - 30\", 7)\r\n",
					"                        .when(df.Result_Bucket == \"49.95 - 40\", 6)\r\n",
					"                        .when(df.Result_Bucket == \"59.95 - 50\", 5)\r\n",
					"                        .when(df.Result_Bucket == \"69.95 - 60\", 4)\r\n",
					"                        .when(df.Result_Bucket == \"79.95 - 70\", 3)\r\n",
					"                        .when(df.Result_Bucket == \"89.95 - 80\", 2)\r\n",
					"                        .when(df.Result_Bucket == \"99.95 - 90\", 1)\r\n",
					"                        .when(df.Result_Bucket == \"No Consent\", 9)\r\n",
					"                        .otherwise(10)\r\n",
					"                    )\r\n",
					"    \r\n",
					"\r\n",
					"    return df"
				],
				"execution_count": null
			}
		]
	}
}