{
	"name": "Transform_Functions_py",
	"properties": {
		"folder": {
			"name": "Stage3"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "spark3p1sm",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "dba70b87-bd76-487e-8c2a-d8ba4d57fbd5"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/09921ef6-5d34-4a25-a233-84ffa9485571/resourceGroups/rg-oea-tceooeadev01/providers/Microsoft.Synapse/workspaces/syn-oea-tceooeadev01/bigDataPools/spark3p1sm",
				"name": "spark3p1sm",
				"type": "Spark",
				"endpoint": "https://syn-oea-tceooeadev01.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/spark3p1sm",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.1",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"from pyspark.sql.functions import when, max, regexp_replace, col, concat_ws, concat, udf, lit, regexp_replace, split, upper, date_format, to_date, first, trim\n",
					"from pyspark.sql.types import StringType\n",
					"from pyspark.sql.window import Window"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMYearLevel_pseudo(df):\n",
					"    # create display name\n",
					"    df = df.withColumn(\"DisplayName\", when(df.BusinessDesc == \"Unknown\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"Ungraded\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"SecondaryUngraded\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"PrimaryUngraded\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"Childcare\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"4yo Kindergarten\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"3yo Kindergarten\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"TwoYearsBeforeYear1\", \"\")\n",
					"                                        .when(df.BusinessDesc == \"Pre-Year 1\", \"Prep\")\n",
					"                                        .when(df.BusinessDesc == \"Pre-School\", \"Prep\")\n",
					"                                        .when(df.BusinessDesc == \"OneYearBeforeYear1\", \"Prep\")\n",
					"                                        .otherwise(df.BusinessDesc)\n",
					"                        )\n",
					"\n",
					"    # create 'short' name \n",
					"    df = df.withColumn(\"ShortName\", when(df.DisplayName == \"\", \"\")\n",
					"                                    .when(df.DisplayName == \"Prep\", \"P\")\n",
					"                                    .otherwise(split(df.DisplayName, \" \")[-1])\n",
					"                        )\n",
					"\n",
					"    return df"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMCampus_pseudo(df):\n",
					"\n",
					"        print(\"Transforming DMCampus\")\n",
					"        df = df.filter(df.DioceseName == 'Townsville') \\\n",
					"                .filter(df.SchoolName !=  'Townsville Catholic Education Office') \\\n",
					"                .filter(df.SchoolName !=  'Canossa Convent School') \\\n",
					"                .filter(df.SchoolName !=  'St Patrick\\'s College Townsville') \\\n",
					"                .filter(df.SchoolId != 6814)\n",
					"        \n",
					"        # load the school list to get the 'area' into DMCampus\n",
					"        sourcep = oea.stage2p\n",
					"        school_df = spark.read.load(sourcep + \"/_SupportData/SchoolList_pseudo\", format='delta')\n",
					"        \n",
					"        school_df = school_df.withColumnRenamed('SchoolId', 'xSchoolId')\n",
					"\n",
					"        df = df.withColumnRenamed('SchoolName', 'xSchoolName')\n",
					"\n",
					"        newdf = df.join(school_df, df.SchoolId == school_df.xSchoolId, \"inner\")\n",
					"        \n",
					"        final_df = newdf.select(col(\"SchoolId\"), col(\"SchoolName\"), col(\"Area\"), col(\"Location\"), \\\n",
					"                                col(\"Team\"), col(\"SchoolType\"), col(\"Boarding\"), col(\"SMYL\"), col(\"LastICSEA\"), \\\n",
					"                                col(\"SKCampus\"), col(\"BKCampusId\"), col(\"CampusSuburbAndName\"), col(\"SchoolSuburbAndName\"))\n",
					"\n",
					"        final_df = final_df.withColumn(\"SchoolNameAndArea\", concat_ws(\" - \", trim(col(\"SchoolName\")), trim(col(\"Area\"))))\n",
					"\n",
					"        return final_df\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMDate_pseudo(df):\n",
					"\n",
					"    sourcep = oea.stage2p\n",
					"\n",
					"    df.createOrReplaceTempView('vw_df_dmdate_pseudo')\n",
					"\n",
					"    calendar_df = spark.read.load(sourcep + \"/ACER/DMCalendarYear_pseudo\", format='delta')\n",
					"\n",
					"    calendar_df.createOrReplaceTempView('vw_df_calendar')\n",
					"\n",
					"    final_df = spark.sql(\"select d.*, c.skyear from vw_df_dmdate_pseudo d left join vw_df_calendar c on d.year = c.year where d.year >= 2008 and d.year <= 2030\")\n",
					"\n",
					"    return final_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMStudent_pseudo(df):\n",
					"\n",
					"    sourcep = oea.stage2p\n",
					"\n",
					"    df.createOrReplaceTempView('vw_df_dmstudent_pseudo')\n",
					"\n",
					"    final_df = spark.sql(\"select * from vw_df_dmstudent_pseudo where length(bksourcestudentid) = 36\")\n",
					"\n",
					"    return final_df"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMNAPLAN_pseudo(df):\n",
					"\n",
					"    sourcep = oea.stage2p\n",
					"\n",
					"    df.createOrReplaceTempView('vw_df_dmnaplan_pseudo')\n",
					"\n",
					"    final_df = spark.sql(\"select * from vw_df_dmnaplan_pseudo where PersistentStudentID <> -1\")\n",
					"\n",
					"    return final_df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMPersonDemographic_pseudo(df):\n",
					"\n",
					"    final_df = df.filter(df.Ceider != -1) \\\n",
					"                .filter( (df.PersonType == \"Student\") | (df.PersonType == \"Staff\") ) \\\n",
					"                .drop(\"UsualTransport\") \\\n",
					"                .drop(\"ContactNotesBH\") \\\n",
					"                .drop(\"ContactNotesAH\") \\\n",
					"                .drop(\"OrganisationUserId\") \\\n",
					"                .drop(\"ProgramCode\") \\\n",
					"                .drop(\"Disability_YN\") \\\n",
					"                .drop(\"DisabilityFundedInt\") \\\n",
					"                .drop(\"ReceivesESL_YN\") \\\n",
					"                .drop(\"ReceivesESLInt\") \\\n",
					"                .drop(\"RequiresESL_YN\") \\\n",
					"                .drop(\"RequresESLInt\") \\\n",
					"                .drop(\"LBOTE_YN\") \\\n",
					"                .drop(\"LBOTEInt\") \\\n",
					"                .drop(\"AccessRestrictions_YN\")\n",
					"\n",
					"    return final_df\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### REMOVE THIS"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMFactPATResults_pseudoREMOVE(df):\n",
					"\n",
					"    sourcep = oea.stage2p\n",
					"\n",
					"    df.createOrReplaceTempView('vw_df_dmfactpatresults_pseudo')\n",
					"\n",
					"    datedetails_df = spark.read.load(sourcep + \"/ACER/DMPATStudentTestGrouping_pseudo\", format='delta')\n",
					"\n",
					"    datedetails_df.createOrReplaceTempView('vw_df_dmpatstudenttestgrouping')\n",
					"\n",
					"    final_df = spark.sql(\"select a.*, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, scalescore, datecomplete, timecomplete, combineddatetime, max(skpatresults) as maxskpatresults from (select a.skpatresults, a.skyear, a.skacerstudent, a.skpattest, a.skcampus,  a.ScaleScore,  b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, combineddatetime, max(scalescore) as maxscalescore from (select a.skyear, a.skacerstudent, a.skpattest, a.skcampus,  a.ScaleScore,  b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from vw_df_dmfactpatresults_pseudo a left join vw_df_dmpatstudenttestgrouping b on a.skpatstudenttestgrouping = b.skpatstudenttestgrouping inner join (select skyear, skacerstudent, skpattest, skcampus, max(concat(datecomplete, ' ', right(left(timecomplete, 10), 8))) as latestdate from (select a.*, orig.skpatstudenttestgrouping, orig.skacerstanine, ScaleScore, skpatresults, b.datecomplete, b.timecomplete, concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) as combineddatetime from (select skyear, skacerstudent, skpattest, skcampus, count(*) as counttotal from vw_df_dmfactpatresults_pseudo where skpattest not in (43, 54, 65, 66, 76, 79, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112) group by skyear, skacerstudent, skpattest, skcampus) a left join vw_df_dmfactpatresults_pseudo orig on a.skyear = orig.skyear and a.skacerstudent = orig.skacerstudent and a.skpattest = orig.skpattest and a.skcampus = orig.skcampus left join vw_df_dmpatstudenttestgrouping b on orig.skpatstudenttestgrouping = b.skpatstudenttestgrouping) total group by skyear, skacerstudent, skpattest, skcampus) inner1 on a.skyear = inner1.skyear and a.skacerstudent = inner1.SKACERStudent and a.SKPATTest = inner1.SKPATTest and a.SKCampus = inner1.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner1.latestdate ) inner2 group by skyear, skacerstudent, skpattest, skcampus, combineddatetime ) inner3 on a.skyear = inner3.skyear and a.skacerstudent = inner3.SKACERStudent and a.SKPATTest = inner3.SKPATTest and a.SKCampus = inner3.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner3.combineddatetime ) inner4 group by skyear, skacerstudent, skpattest, skcampus, scalescore, datecomplete, timecomplete, combineddatetime ) inner5 on a.skyear = inner5.skyear and a.skacerstudent = inner5.SKACERStudent and a.SKPATTest = inner5.SKPATTest and a.SKCampus = inner5.SKCampus and concat(b.datecomplete, ' ', right(left(b.timecomplete, 10), 8)) = inner5.combineddatetime and a.SKPATResults = inner5.maxskpatresults\")\n",
					"\n",
					"    return final_df\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMFactPATResults_pseudo(df):\n",
					"    # Create a window specification for ordering rows\n",
					"    window_spec = Window.partitionBy('SKYear', 'SKYearLevel', 'SKPATTest').orderBy('NormMeanScaledScore')\n",
					"\n",
					"    df = df.withColumn('NormMeanScaledScore', when(col('NormMeanScaledScore').isNull(), first(col('NormMeanScaledScore'), ignorenulls=True).over(window_spec)).otherwise(col('NormMeanScaledScore')))\n",
					"\n",
					"    return df\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def DMPATTest_pseudo(df):\n",
					"    df = df.withColumn('SummaryGroups', when(df.PATTestName == \"PAT Maths 4th Edition\", \"Maths\")\n",
					"                                        .when(df.PATTestName == \"PAT Maths Plus\", \"Maths\")\n",
					"                                        .when(df.PATTestName == \"PAT Maths Adaptive\", \"Maths\")\n",
					"                                        .when(df.PATTestName == \"PAT Reading 5th Edition\", \"Reading\")\n",
					"                                        .when(df.PATTestName == \"PAT-R Comprehension\", \"Reading\")\n",
					"                                        .when(df.PATTestName == \"PAT Reading Adaptive\", \"Reading\")\n",
					"                                        .otherwise(\"Other\")\n",
					"                        )\n",
					"    return df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def CompassODSStudentOrganisationMilestones_pseudo(df):\n",
					"\n",
					"    # this will get a the first substring up to the first hyphen \n",
					"    get_substring_udf = udf(lambda x: x.split(\"-\")[0] if \"-\" in x else x, StringType())\n",
					"\n",
					"    df = df.withColumn('xOrganisationName', get_substring_udf(col('OrganisationName')))\n",
					"    df = df.drop('OrganisationName')\n",
					"    df = df.withColumnRenamed('xOrganisationName', 'OrganisationName')\n",
					"\n",
					"    return df\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Early Years Testing"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def EarlyYearsResults_pseudo(df):\n",
					"\n",
					"    # filter out the in-progress tests (incomplete tests)\n",
					"    df = df.filter(df.Status == \"Completed\")\n",
					"\n",
					"    question_columns = [item for item in df.columns if item.startswith('Ques')]\n",
					"\n",
					"    for col in question_columns:\n",
					"            df = df.withColumn(col, when(df[col] == 'Correct', lit('1'))\n",
					"                                .otherwise(when(df[col] == 'Incorrect', lit('0'))\n",
					"                                .otherwise(when(df[col] == 'Used structure correctly', lit('1'))\n",
					"                                .otherwise(when(df[col] == 'Used structure incorrectly', lit('0'))\n",
					"                                .otherwise(when(df[col] == 'Other response', lit('0')))))))\n",
					"  \n",
					"    # replace errors in classes\n",
					"    df = df.withColumn('ClassID', regexp_replace('ClassID', 'GENP_PREP', '00GENP01'))\n",
					"    df = df.withColumn('ClassID', regexp_replace('ClassID', 'GEN1_Year 1', '01GEN101'))\n",
					"   \n",
					"    return df\n",
					"\n",
					"\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def EarlyYearsResultsYear2_pseudo(df):\n",
					"\n",
					"    # filter out the in-progress tests (incomplete tests)\n",
					"    df = df.filter(df.Status == \"Completed\")\n",
					"\n",
					"    df = df.withColumn('Ques1', when(df.Ques1.substr(1,5) == 'could', lit('could good')).otherwise(df.Ques1))\n",
					"\n",
					"    df = df.withColumn('ClassID', regexp_replace('ClassID', 'GEN2_Year 2', '02GEN201'))\n",
					"\n",
					"    #df = df.withColumn('ClassId', when(df.Ceider == '769425243', lit('GEN2_02C')).otherwise(df.ClassID))\n",
					"\n",
					"    return df\n",
					"\n",
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Senior Outcomes "
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def ATAR_pseudo(df):\n",
					"    df = df.withColumn(\"Result_Bucket\", \n",
					"                        when(df.Given_Name == \"No Consent\", \"No Consent\")\n",
					"                        .when(df.Given_Name == \"Vocational Pathway\", \"Vocational Pathway\")\n",
					"                        .otherwise(when(df.ATAR < 30, \"< 30\")\n",
					"                                    .when(((df.ATAR < 40) & (df.ATAR >= 30)), \"39.95 - 30\")\n",
					"                                    .when(((df.ATAR < 50) & (df.ATAR >= 40)), \"49.95 - 40\")\n",
					"                                    .when(((df.ATAR < 60) & (df.ATAR >= 50)), \"59.95 - 50\")\n",
					"                                    .when(((df.ATAR < 70) & (df.ATAR >= 60)), \"69.95 - 60\")\n",
					"                                    .when(((df.ATAR < 80) & (df.ATAR >= 70)), \"79.95 - 70\")\n",
					"                                    .when(((df.ATAR < 90) & (df.ATAR >= 80)), \"89.95 - 80\")\n",
					"                                    .when(df.ATAR >= 90, \"99.95 - 90\")\n",
					"                                )\n",
					"                    )\n",
					"\n",
					"    df = df.withColumn(\"Order\", \n",
					"                        when(df.Result_Bucket == \"< 30\", 8)\n",
					"                        .when(df.Result_Bucket == \"39.95 - 30\", 7)\n",
					"                        .when(df.Result_Bucket == \"49.95 - 40\", 6)\n",
					"                        .when(df.Result_Bucket == \"59.95 - 50\", 5)\n",
					"                        .when(df.Result_Bucket == \"69.95 - 60\", 4)\n",
					"                        .when(df.Result_Bucket == \"79.95 - 70\", 3)\n",
					"                        .when(df.Result_Bucket == \"89.95 - 80\", 2)\n",
					"                        .when(df.Result_Bucket == \"99.95 - 90\", 1)\n",
					"                        .when(df.Result_Bucket == \"No Consent\", 9)\n",
					"                        .otherwise(10)\n",
					"                    )\n",
					"    \n",
					"    # also create a SK ID that will connect to the senior outcomes table\n",
					"    df = df.withColumn(\"SKShortID\", upper(concat_ws(\"-\", \"SchoolId\", \"Year\", \"Family_Name\", \"Given_Name\")))\n",
					"\n",
					"    return df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def StudentLevel_pseudo(df):\n",
					"    df = df.withColumn(\"CampusID\", \n",
					"                        when(df.centre_code == 1591, 15370)\n",
					"                        .when(df.centre_code == 1653, 17253)\n",
					"                        .when(df.centre_code == 5328, 17227)\n",
					"                        .when(df.centre_code == 5331, 2529)\n",
					"                        .when(df.centre_code == 5373, 13492)\n",
					"                        .when(df.centre_code == 5421, 17223)\n",
					"                        .when(df.centre_code == 5422, 17240)\n",
					"                        .when(df.centre_code == 5429, 17225)\n",
					"                        .when(df.centre_code == 5434, 17247)\n",
					"                        .when(df.centre_code == 7578, 550)\n",
					"                    )\n",
					"    \n",
					"    #df = df.withColumn(\"FirstNameOnly\", when(\"given_names\".contains(\" \"), split(\"given_names\", \" \").getItem(0)).otherwise(\"given_names\"))\n",
					"\n",
					"    df = df.withColumn(\"SKLongID\", upper(concat_ws(\"-\", split(\"last_name\", \" \").getItem(0), split(\"given_names\", \" \").getItem(0), \"birth_date\")))\n",
					"\n",
					"    return df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def CompassODSStudentDemographicFull_pseudo(df):\n",
					"    \"\"\" create the SKLongID column for the ODS Student Demographics table \"\"\"\n",
					"\n",
					"    # clean up the data of birth column\n",
					"    df = df.withColumn(\"DOB_YearFirstFormat\", to_date(col(\"DateOfBirth\")))\n",
					"\n",
					"    df = df.withColumn(\"DOB\", date_format(\"DOB_YearFirstFormat\", \"dd/MM/yyyy\"))\n",
					"\n",
					"    df = df.withColumn(\"SKLongID\", upper(concat_ws(\"-\", split(\"LastName\", \" \").getItem(0), split(\"FirstName\", \" \").getItem(0), \"DOB\")))\n",
					"\n",
					"    df = df.drop(\"DOB_YearFirstFormat\", \"DOB\")\n",
					"\n",
					"    # filter for isCurrent records only\n",
					"    df = df.filter(col(\"Iscurrent\") == \"True\")\n",
					"\n",
					"    return df"
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def AEResultsCombined(df):\n",
					"    # create an extra column to combine year and semester into one value\n",
					"    df = df.withColumn('YearSemesterValue', concat('Year', 'Semester'))\n",
					"    df = df.withColumn(\"YearSemesterDescription\", concat(df.Year, lit(\" Semester \"), df.Semester))\n",
					"\n",
					"    df = df.withColumn(\"UniversalResult\", when(df.Result == \"A\", \"A/AP\") \n",
					"                                            .when(df.Result == \"B\", \"B/MC\")\n",
					"                                            .when(df.Result == \"C\", \"C/WW\")\n",
					"                                            .when(df.Result == \"D\", \"D/EX\")\n",
					"                                            .when(df.Result == \"E\", \"E/BA\")\n",
					"                                            .when(df.Result == \"AP\", \"A/AP\")\n",
					"                                            .when(df.Result == \"MC\", \"B/MC\")\n",
					"                                            .when(df.Result == \"WW\", \"C/WW\")\n",
					"                                            .when(df.Result == \"EX\", \"D/EX\")\n",
					"                                            .when(df.Result == \"BA\", \"E/BA\")\n",
					"                                            .otherwise(df.Result)\n",
					"                                            \n",
					"                        )\n",
					"\n",
					"    return df"
				],
				"execution_count": null
			}
		]
	}
}